{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import bs4 \n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import io\n",
    "import csv\n",
    "\n",
    "\n",
    "response = requests.get(\"https://www.drugs.com/drug_information.html\")\n",
    "response = response.text\n",
    "data = bs4.BeautifulSoup(response, \"lxml\")\n",
    "read1 = data.select(\".ddc-paging\")\n",
    "\n",
    "\n",
    "\n",
    "alp_url = []\n",
    "for i in range(len(read1)):\n",
    "    x = read1[i].find_all(\"li\")\n",
    "    for j in range(len(x)):\n",
    "        y = x[j].find_all(\"a\")\n",
    "        for k in range(len(y)):\n",
    "            z = y[k].get(\"href\")\n",
    "            alp_url.append(\"https://www.drugs.com/\" +str(z))        \n",
    "print(alp_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alp_2_url = []\n",
    "for m in range(len(alp_url)):\n",
    "    response = ''\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(alp_url[m])\n",
    "            break\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n",
    "    \n",
    "    response = response.text\n",
    "    data = bs4.BeautifulSoup(response, 'lxml')\n",
    "    read2 = data.select(\".ddc-paging\")\n",
    "    for i in range(len(read2)):\n",
    "        x = read2[i].find_all(\"li\")\n",
    "        for j in range(len(x)):\n",
    "            y = x[j].find_all(\"a\")\n",
    "            for k in range(len(y)):\n",
    "                z = y[k].get(\"href\")\n",
    "                alp_2_url.append(\"https://www.drugs.com/\" +str(z))\n",
    "                print(\"https://www.drugs.com/\" +str(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alp_3_url = []\n",
    "for m in range(len(alp_2_url)):\n",
    "    response = ''\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(alp_2_url[m])\n",
    "            break\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 3 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(3)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    response = response.text\n",
    "    data = bs4.BeautifulSoup(response, 'lxml')\n",
    "    read3 = data.select(\".ddc-list-column-2\")\n",
    "    for i in range(len(read3)):\n",
    "        x = read3[i].find_all(\"li\")\n",
    "        for j in range(len(x)):\n",
    "            y = x[j].find_all(\"a\")\n",
    "            for k in range(len(y)):\n",
    "                z = y[k].get(\"href\")\n",
    "                alp_3_url.append(\"https://www.drugs.com/\" +str(z))\n",
    "                print(\"https://www.drugs.com/\" +str(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(alp_3_url)):\n",
    "    response = ''\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(alp_3_url[n])\n",
    "            break\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 3 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(3)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n",
    "    response = response.text\n",
    "    data = bs4.BeautifulSoup(response, 'lxml')\n",
    "    check = data.find('div', {'class': 'contentBox'})\n",
    "\n",
    "\n",
    "    start=[]\n",
    "    for headings in check.find_all('h2' ):\n",
    "        start.append(headings.text)\n",
    "\n",
    "    total_text = check.text\n",
    "    \n",
    "    if len(start) >= 12:\n",
    "        med_what_is = (total_text.split(start[0]))[1].split(start[1])[0]\n",
    "        med_given = (total_text.split(start[3]))[1].split(start[4])[0]\n",
    "        med_side_affect = (total_text.split(start[8]))[1].split(start[9])[0]\n",
    "        med_other_drug_affect = (total_text.split(start[10]))[1].split(start[11])[0]\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "    with io.open('drugs_com.csv', 'a', encoding = \"UTF-8\") as f2:\n",
    "            f2.write((' '.join(med_what_is.split())) + \",\" + (' '.join(med_given.split())) + \",\" + (' '.join(med_side_affect.split())) + \",\" + (' '.join(med_other_drug_affect.split()))+ \",\"+ \"\\n\")\n",
    "            f2.close() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
